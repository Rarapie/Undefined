import pandas as pd
import joblib
import argparse
import os
import sys


def predict(args):
    # ==========================================
    # 1. Check if core files exist
    # ==========================================
    if not os.path.exists(args.model):
        print(f"Error: Model file not found -> {args.model}")
        print("Please ensure you have run the training script and generated 'models/final_model.pkl'.")
        sys.exit(1)

    if not os.path.exists(args.features):
        print(f"Error: Feature list file not found -> {args.features}")
        print(
            "Please ensure you have run the training script and generated 'results/boruta_features/selected_features.csv'.")
        sys.exit(1)

    # ==========================================
    # 2. Load model and feature list
    # ==========================================
    print(f"Loading model: {args.model} ...")
    try:
        model = joblib.load(args.model)
    except Exception as e:
        print(f"Failed to load model: {e}")
        sys.exit(1)

    print(f"Loading feature list: {args.features} ...")
    try:
        # Attempt to read the feature CSV.
        # Handling cases with/without headers based on how pandas saved the Series.
        feature_df = pd.read_csv(args.features, header=None)

        # If the first row looks like a header (e.g., '0' or 'feature'), reload with header=0
        if str(feature_df.iloc[0, 0]) in ['0', 'feature', 'features']:
            feature_df = pd.read_csv(args.features, header=0)

        required_features = feature_df.iloc[:, 0].astype(str).tolist()
        print(f"Model requires {len(required_features)} features.")

    except Exception as e:
        print(f"Failed to load feature list: {e}")
        sys.exit(1)

    # ==========================================
    # 3. Read and validate input data
    # ==========================================
    print(f"Reading input data: {args.input} ...")
    try:
        # Assuming the first column is the Sample ID
        input_df = pd.read_csv(args.input, index_col=0)
    except Exception as e:
        print(f"Failed to read input file: {e}")
        sys.exit(1)

    # Check for missing features
    missing_cols = [col for col in required_features if col not in input_df.columns]
    if missing_cols:
        print(f"\nError: Input file is missing {len(missing_cols)} features required by the model!")
        print(f"Missing features examples: {missing_cols[:5]} ...")
        sys.exit(1)

    # ==========================================
    # 4. Feature Alignment
    # ==========================================
    # Force the column order to match the training phase
    X_input = input_df[required_features]

    print("Data validation passed. Features aligned.")

    # ==========================================
    # 5. Prediction
    # ==========================================
    print("Starting prediction...")
    try:
        predictions = model.predict(X_input)
    except Exception as e:
        print(f"Error during prediction: {e}")
        sys.exit(1)

    # ==========================================
    # 6. Save Results
    # ==========================================
    output_df = pd.DataFrame({
        'Sample_ID': input_df.index,
        'Predicted_Value': predictions
    })

    output_df.to_csv(args.output, index=False)
    print(f"\nPrediction complete! Results saved to: {args.output}")
    print("-" * 30)
    print(output_df.head())
    print("-" * 30)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Boruta Model Prediction Tool")

    parser.add_argument("--input", required=True,
                        help="Path to input CSV file (First column is ID, must contain Boruta-selected features)")
    parser.add_argument("--output", default="predictions.csv", help="Path to save the prediction results")

    # Default paths point to the structure generated by your training code
    parser.add_argument("--model", default="./final_model.pkl", help="Path to the trained model file")
    parser.add_argument("--features", default="./selected_features.csv",
                        help="Path to the selected features list")

    args = parser.parse_args()

    predict(args)